#!/usr/bin/env python3

# ============================================================================ #
"""
GPT Math Syntax Converter Core:
Shared conversion engine used by single-file and batch CLI scripts.
Converts common LaTeX-like patterns generated by ChatGPT into KaTeX-compatible
Markdown while preserving regions that should never be touched.

Protected regions:
- YAML frontmatter
- Fenced code blocks
- Inline code spans
- Markdown links/images
- Existing $...$ and $$...$$ math blocks

Author: Codex (GPT-5)
Version: 1.0.0
"""
# ============================================================================ #

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
import re
import shutil
import tempfile


FENCE_START_RE = re.compile(r"^[ \t]{0,3}(`{3,}|~{3,})")
LINK_OR_IMAGE_RE = re.compile(r"!?\[[^\]\n]*\]\([^\)\n]*\)")
ESCAPED_DISPLAY_RE = re.compile(r"\\\[(.+?)\\\]", re.DOTALL)
ESCAPED_INLINE_RE = re.compile(r"\\\((.+?)\\\)", re.DOTALL)
BARE_BRACKET_LINE_RE = re.compile(
    r"(?m)^(?P<indent>[ \t]{0,3})\[(?P<body>[^\n\[\]]+)\][ \t]*$"
)
PAREN_GROUP_RE = re.compile(r"(?<![A-Za-z0-9_\\])\(([^()\n]{1,400})\)(?![A-Za-z0-9_])")
LATEX_COMMAND_RE = re.compile(r"\\[A-Za-z]+")
SUBSUP_MARKER_RE = re.compile(
    r"(?:[A-Za-z0-9\}\)\]])\s*[_^]\s*(?:\{[^{}\n]+\}|[A-Za-z0-9])"
)
OPERATOR_SUBSCRIPT_RE = re.compile(
    r"(?<![\w$\\])(?:\\)?(?P<op>min|max|sum|prod|lim|inf|sup)_(?P<sub>[A-Za-z0-9]+)(?![\w])"
)


@dataclass
class ConversionStats:
    escaped_display: int = 0
    escaped_inline: int = 0
    bare_bracket_lines: int = 0
    parenthesized_latex: int = 0
    operator_subscripts: int = 0

    @property
    def total(self) -> int:
        """Return the total number of conversions across all categories."""
        return (
            self.escaped_display
            + self.escaped_inline
            + self.bare_bracket_lines
            + self.parenthesized_latex
            + self.operator_subscripts
        )

    def merge(self, other: "ConversionStats") -> None:
        """Accumulate counters from another stats object."""
        self.escaped_display += other.escaped_display
        self.escaped_inline += other.escaped_inline
        self.bare_bracket_lines += other.bare_bracket_lines
        self.parenthesized_latex += other.parenthesized_latex
        self.operator_subscripts += other.operator_subscripts


class _PlaceholderStore:
    def __init__(self) -> None:
        """Initialize internal placeholder storage."""
        self._entries: list[tuple[str, str]] = []

    def add(self, value: str) -> str:
        """Store a protected span and return its placeholder token."""
        token = f"\x00MATHFIX{len(self._entries)}\x00"
        self._entries.append((token, value))
        return token

    def restore(self, text: str) -> str:
        """Restore all previously stored placeholders in the given text."""
        restored = text
        for token, original in self._entries:
            restored = restored.replace(token, original)
        return restored


def _is_escaped(text: str, index: int) -> bool:
    """Return True when character at index is escaped by backslashes."""
    backslashes = 0
    pos = index - 1
    while pos >= 0 and text[pos] == "\\":
        backslashes += 1
        pos -= 1
    return backslashes % 2 == 1


def _looks_like_math(expression: str) -> bool:
    """Heuristically detect math-like content for bare bracket lines."""
    body = expression.strip()
    if not body:
        return False
    if LATEX_COMMAND_RE.search(body):
        return True
    if SUBSUP_MARKER_RE.search(body):
        return True
    if any(symbol in body for symbol in ("=", "<", ">", "≤", "≥", "≠", "≈")):
        return bool(re.search(r"[A-Za-z0-9]", body))
    return False


def _looks_like_parenthesized_latex(expression: str) -> bool:
    """Heuristically detect LaTeX-like content inside parentheses."""
    body = expression.strip()
    if not body:
        return False
    if LATEX_COMMAND_RE.search(body):
        return True
    if SUBSUP_MARKER_RE.search(body):
        return True
    return False


def _format_inline_math(body: str) -> str:
    """Wrap content with inline math delimiters."""
    return f"${body.strip()}$"


def _format_display_math(body: str) -> str:
    """Wrap content with display math delimiters."""
    stripped = body.strip()
    if "\n" in stripped:
        return f"$$\n{stripped}\n$$"
    return f"$${stripped}$$"


def _mask_inline_code(text: str, store: _PlaceholderStore) -> str:
    """Replace inline code spans with placeholders to avoid rewrites."""
    output: list[str] = []
    index = 0
    length = len(text)

    while index < length:
        if text[index] != "`":
            output.append(text[index])
            index += 1
            continue

        tick_start = index
        while index < length and text[index] == "`":
            index += 1
        delimiter = text[tick_start:index]

        closing = text.find(delimiter, index)
        if closing == -1:
            output.append(delimiter)
            continue

        span = text[tick_start : closing + len(delimiter)]
        output.append(store.add(span))
        index = closing + len(delimiter)

    return "".join(output)


def _mask_existing_dollar_math(text: str, store: _PlaceholderStore) -> str:
    """Mask existing $...$ and $$...$$ spans before conversion passes."""
    output: list[str] = []
    index = 0
    length = len(text)

    while index < length:
        char = text[index]
        if char != "$" or _is_escaped(text, index):
            output.append(char)
            index += 1
            continue

        is_double = index + 1 < length and text[index + 1] == "$"
        delimiter = "$$" if is_double else "$"
        step = 2 if is_double else 1
        search = index + step
        found = -1

        while search < length:
            if text[search] != "$" or _is_escaped(text, search):
                search += 1
                continue

            if is_double:
                if search + 1 < length and text[search + 1] == "$":
                    found = search
                    break
                search += 1
            else:
                found = search
                break

        if found == -1:
            output.append(char)
            index += 1
            continue

        end = found + step
        span = text[index:end]
        output.append(store.add(span))
        index = end

    return "".join(output)


def _split_frontmatter(text: str) -> tuple[str | None, str]:
    """Split YAML frontmatter from body when a valid header is present."""
    if not text:
        return None, text

    lines = text.splitlines(keepends=True)
    if not lines or lines[0].strip() != "---":
        return None, text

    has_mapping_like_line = False
    offset = len(lines[0])
    for line in lines[1:]:
        offset += len(line)
        if ":" in line:
            has_mapping_like_line = True
        if line.strip() in ("---", "..."):
            if has_mapping_like_line:
                return text[:offset], text[offset:]
            return None, text

    return None, text


def _is_fence_closer(line: str, fence_char: str, fence_len: int) -> bool:
    """Return True if a line closes the currently open fenced code block."""
    stripped = line.lstrip(" \t")
    if not stripped.startswith(fence_char * fence_len):
        return False

    run_len = 0
    while run_len < len(stripped) and stripped[run_len] == fence_char:
        run_len += 1

    if run_len < fence_len:
        return False

    remainder = stripped[run_len:].strip()
    return remainder == ""


def _split_protected_segments(text: str) -> list[tuple[bool, str]]:
    """Split text into protected and plain segments for safe processing."""
    frontmatter, body = _split_frontmatter(text)
    segments: list[tuple[bool, str]] = []

    if frontmatter is not None:
        segments.append((True, frontmatter))

    lines = body.splitlines(keepends=True)
    plain_buffer: list[str] = []
    fence_buffer: list[str] = []
    in_fence = False
    fence_char = ""
    fence_len = 0

    def flush_plain() -> None:
        if plain_buffer:
            segments.append((False, "".join(plain_buffer)))
            plain_buffer.clear()

    def flush_fence() -> None:
        if fence_buffer:
            segments.append((True, "".join(fence_buffer)))
            fence_buffer.clear()

    for line in lines:
        if not in_fence:
            match = FENCE_START_RE.match(line)
            if match:
                flush_plain()
                marker = match.group(1)
                in_fence = True
                fence_char = marker[0]
                fence_len = len(marker)
                fence_buffer.append(line)
            else:
                plain_buffer.append(line)
            continue

        fence_buffer.append(line)
        if _is_fence_closer(line, fence_char, fence_len):
            in_fence = False
            flush_fence()

    if in_fence:
        flush_fence()
    else:
        flush_plain()

    return segments


class MarkdownMathConverter:
    def __init__(self, convert_operator_subscripts: bool = True) -> None:
        """Create a converter with optional operator-subscript rewriting."""
        self.convert_operator_subscripts = convert_operator_subscripts

    def convert_text(self, content: str) -> tuple[str, ConversionStats]:
        """Convert full Markdown content and return converted text plus stats."""
        segments = _split_protected_segments(content)
        merged_stats = ConversionStats()
        output_parts: list[str] = []

        for is_protected, segment in segments:
            if is_protected:
                output_parts.append(segment)
                continue

            converted, stats = self._convert_plain_segment(segment)
            merged_stats.merge(stats)
            output_parts.append(converted)

        return "".join(output_parts), merged_stats

    def _convert_plain_segment(self, text: str) -> tuple[str, ConversionStats]:
        """Convert one non-protected segment with ordered regex passes."""
        stats = ConversionStats()
        placeholders = _PlaceholderStore()
        working = text

        working = _mask_inline_code(working, placeholders)
        working = LINK_OR_IMAGE_RE.sub(lambda m: placeholders.add(m.group(0)), working)
        working = _mask_existing_dollar_math(working, placeholders)

        def replace_escaped_display(match: re.Match[str]) -> str:
            inner = match.group(1)
            if not inner.strip():
                return match.group(0)
            stats.escaped_display += 1
            return _format_display_math(inner)

        working = ESCAPED_DISPLAY_RE.sub(replace_escaped_display, working)

        def replace_escaped_inline(match: re.Match[str]) -> str:
            inner = match.group(1)
            if not inner.strip():
                return match.group(0)
            stats.escaped_inline += 1
            if "\n" in inner:
                return _format_display_math(inner)
            return _format_inline_math(inner)

        working = ESCAPED_INLINE_RE.sub(replace_escaped_inline, working)

        def replace_bare_bracket_line(match: re.Match[str]) -> str:
            body = match.group("body")
            if not _looks_like_math(body):
                return match.group(0)
            stats.bare_bracket_lines += 1
            return f"{match.group('indent')}{_format_display_math(body)}"

        working = BARE_BRACKET_LINE_RE.sub(replace_bare_bracket_line, working)

        def replace_parenthesized_latex(match: re.Match[str]) -> str:
            body = match.group(1)
            stripped = body.strip()
            if stripped.lower() in {"i.e.", "e.g.", "etc"}:
                return match.group(0)
            if "$" in stripped or "\x00MATHFIX" in stripped:
                return match.group(0)
            if not _looks_like_parenthesized_latex(stripped):
                return match.group(0)
            stats.parenthesized_latex += 1
            return _format_inline_math(stripped)

        working = PAREN_GROUP_RE.sub(replace_parenthesized_latex, working)

        if self.convert_operator_subscripts:
            def replace_operator_subscript(match: re.Match[str]) -> str:
                stats.operator_subscripts += 1
                return f"$\\{match.group('op')}_{{{match.group('sub')}}}$"

            working = OPERATOR_SUBSCRIPT_RE.sub(replace_operator_subscript, working)

        converted = placeholders.restore(working)
        return converted, stats


def convert_markdown_file(
    file_path: Path, converter: MarkdownMathConverter
) -> tuple[str, str, ConversionStats, bool]:
    """Read, convert, and diff one Markdown file."""
    original = file_path.read_text(encoding="utf-8")
    converted, stats = converter.convert_text(original)
    changed = converted != original
    return original, converted, stats, changed


def write_text_atomic(file_path: Path, content: str) -> None:
    """Atomically replace a file by writing to a temp file then renaming."""
    temp_handle = tempfile.NamedTemporaryFile(
        mode="w",
        encoding="utf-8",
        dir=str(file_path.parent),
        prefix=f".{file_path.name}.",
        suffix=".tmp",
        delete=False,
    )
    temp_path = Path(temp_handle.name)
    try:
        with temp_handle:
            temp_handle.write(content)
            temp_handle.flush()
        temp_path.replace(file_path)
    except Exception:
        if temp_path.exists():
            temp_path.unlink()
        raise


def backup_file(file_path: Path, backup_path: Path) -> None:
    """Create/update a backup copy of file_path at backup_path."""
    backup_path.parent.mkdir(parents=True, exist_ok=True)
    shutil.copy2(file_path, backup_path)

# ============================================================================ #
# End of GPT_math_syntax_converter.py
